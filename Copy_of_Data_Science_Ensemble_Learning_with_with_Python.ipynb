{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Data_Science_Ensemble_Learning_with_with_Python.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "BA_HMQbPHWQJ",
        "SPpfqZYzrKvs",
        "5YzXyzh8zmiM",
        "dKTC_Q4g52G1",
        "btf3OzyS52G8",
        "vjn6CpvU52G_",
        "eaPL6iDf7JIA",
        "tqWcOlZ97JIB",
        "rZdaSxPNmxW9",
        "PfdApR7Jmzm9",
        "1eBPjiM8m14s",
        "wBSYp3fVIupH",
        "uebT2koxr4V4",
        "B-eE6btO3KKM"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cherotich/ensemble_learning/blob/main/Copy_of_Data_Science_Ensemble_Learning_with_with_Python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IR_TNDR4xihI"
      },
      "source": [
        "<font color=\"blue\">To use this notebook on Google Colaboratory, you will need to make a copy of it. Go to **File** > **Save a Copy in Drive**. You can then use the new copy that will appear in the new tab.</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcVE8EgKxl2r"
      },
      "source": [
        "# AfterWork Data Science: Ensemble Learning with with Python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BA_HMQbPHWQJ"
      },
      "source": [
        "## Importing the Necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moay-lWZm7z1"
      },
      "source": [
        "# We will start by importing the necessary libraries\n",
        "# ---\n",
        "# \n",
        "import pandas as pd                # Pandas for data manipulation\n",
        "import numpy as np                 # Numpy for scientific computations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPpfqZYzrKvs"
      },
      "source": [
        "## Examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YzXyzh8zmiM"
      },
      "source": [
        "### <font color=\"blue\">Classification</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyugRGHN52Gv"
      },
      "source": [
        "# Example \n",
        "# ---\n",
        "# Question: Will John, 40 years old with a salary of 2500 will buy a car?\n",
        "# ---\n",
        "# Dataset url = http://bit.ly/SocialNetworkAdsDataset\n",
        "# ---"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKTC_Q4g52G1"
      },
      "source": [
        "##### Data Importation and Exploration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0nv0nTv52G2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "d30d7e8c-99be-4650-8d0f-c03ddd38017f"
      },
      "source": [
        "# Loading and previewing our dataset\n",
        "# ---\n",
        "# \n",
        "social_df = pd.read_csv('http://bit.ly/SocialNetworkAdsDataset')\n",
        "social_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>User ID</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Purchased</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15624510</td>\n",
              "      <td>Male</td>\n",
              "      <td>19</td>\n",
              "      <td>19000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>15810944</td>\n",
              "      <td>Male</td>\n",
              "      <td>35</td>\n",
              "      <td>20000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>15668575</td>\n",
              "      <td>Female</td>\n",
              "      <td>26</td>\n",
              "      <td>43000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>15603246</td>\n",
              "      <td>Female</td>\n",
              "      <td>27</td>\n",
              "      <td>57000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>15804002</td>\n",
              "      <td>Male</td>\n",
              "      <td>19</td>\n",
              "      <td>76000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    User ID  Gender  Age  EstimatedSalary  Purchased\n",
              "0  15624510    Male   19            19000          0\n",
              "1  15810944    Male   35            20000          0\n",
              "2  15668575  Female   26            43000          0\n",
              "3  15603246  Female   27            57000          0\n",
              "4  15804002    Male   19            76000          0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5H9l0Kdt52G5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fcb1055-3d78-428f-a98c-bc92f830488f"
      },
      "source": [
        "# Determining the size of our dataset\n",
        "# (records, columns)\n",
        "# ---\n",
        "# \n",
        "social_df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(400, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btf3OzyS52G8"
      },
      "source": [
        "##### Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rwVc4cJ52G8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "d2d008f8-fb51-4b3d-9ad4-4252bd0614d4"
      },
      "source": [
        "# Normally during this stage we would perform quite a number of \n",
        "# procedures, but because our focus is only onlearning about the \n",
        "# different modeling algorithms, we will only perform once \n",
        "# essential step in ot dataset. We will perform encoding,\n",
        "# which will help us transform our categorical values in our \n",
        "# dataset into numerical values. \n",
        "# Lets see what happens when we encode the gender variable \n",
        "# to have only numerical values. \n",
        "# ---\n",
        "#\n",
        "social_df[\"Gender\"] = np.where(social_df[\"Gender\"].str.contains(\"Male\", \"Female\"), 1, 0)\n",
        "social_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>User ID</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Purchased</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15624510</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>19000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>15810944</td>\n",
              "      <td>1</td>\n",
              "      <td>35</td>\n",
              "      <td>20000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>15668575</td>\n",
              "      <td>0</td>\n",
              "      <td>26</td>\n",
              "      <td>43000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>15603246</td>\n",
              "      <td>0</td>\n",
              "      <td>27</td>\n",
              "      <td>57000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>15804002</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>76000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    User ID  Gender  Age  EstimatedSalary  Purchased\n",
              "0  15624510       1   19            19000          0\n",
              "1  15810944       1   35            20000          0\n",
              "2  15668575       0   26            43000          0\n",
              "3  15603246       0   27            57000          0\n",
              "4  15804002       1   19            76000          0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Syffwt5XoEBO"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjn6CpvU52G_"
      },
      "source": [
        "##### Data Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybg1VYOGSXbr"
      },
      "source": [
        "# Preparing our dataset for training\n",
        "# ---\n",
        "# We first divide our data into attributes and labels:\n",
        "# You can think of this as splitting our data set in dependent and independent variables \n",
        "# where Age and EstimatedSalary are the independent variables and Purchased are the dependent/label variable.\n",
        "# ---\n",
        "# \n",
        "X = social_df.iloc[:, [1, 2 ,3]].values  # Independent/predictor variables\n",
        "y = social_df.iloc[:, 4].values          # Dependent/label variable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFyZcCeVScEp"
      },
      "source": [
        "# Splitting the dataset into a training set and test set\n",
        "# ---\n",
        "# We will split our dataset into training data and test data. \n",
        "# Training data will be used to train our logistic model and test data will be used to validate our model\n",
        "# Because we’ll use sklearn to split our data, we will import train_test_split from sklearn.model_selection\n",
        "# ---\n",
        "# \n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sgn73UwVS9hf"
      },
      "source": [
        "# Feature Scaling / Normalisation\n",
        "# ---\n",
        "# We then perform feature scaling / normalisation to scale our data between 0 and 1 so as to get better accuracy.\n",
        "# Here, scaling is important because there is a huge difference between Age and EstimatedSalary.\n",
        "# In addition, this would also reduce redundacy in our dataset. \n",
        "# ---\n",
        "# \n",
        "\n",
        "# We import our scaler from sklearn\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# We make an instance sc_X of the object StandardScaler.\n",
        "# You can think of making an instance as making a copy.\n",
        "sc_X = StandardScaler()\n",
        "\n",
        "# We then fit and transform X_train and X_test\n",
        "X_train = sc_X.fit_transform(X_train)\n",
        "X_test = sc_X.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cDNlsiGTaRF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "f214d350-3ca0-4822-fb6d-bfadc5a86128"
      },
      "source": [
        "# In this example, because we will be comparing how \n",
        "# the different classification models will perform\n",
        "# ---\n",
        "#\n",
        "from sklearn.linear_model import LogisticRegression # Logistic Regression Classifier\n",
        "from sklearn.tree import DecisionTreeClassifier     # Decision Tree Classifier\n",
        "from sklearn.svm import SVC                         # SVM Classifier\n",
        "from sklearn.naive_bayes import GaussianNB          # Naive Bayes Classifier\n",
        "from sklearn.neighbors import KNeighborsClassifier  # KNN Classifier\n",
        "\n",
        "# We will also use our ensemble classifiers\n",
        "from sklearn.ensemble import BaggingClassifier           # Bagging Meta-Estimator Classifier\n",
        "from sklearn.ensemble import RandomForestClassifier      # RandomForest Classifier \n",
        "from sklearn.ensemble import AdaBoostClassifier          # AdaBoost Classifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier  # AdaBoost GradientBoostingClassifier\n",
        "import xgboost as xgb                                    # Importing the XGBoost librariy\n",
        "\n",
        "# Below, we make an instance classifier of the object LogisticRegression, \n",
        "# DecisionTreeClassifier, SVC, GaussianNB, KNeighborsClassifier, GaussianNB.\n",
        "# As we will get to see, each of the classifiers take different parameters.\n",
        "# ---\n",
        "# \n",
        "logistic_classifier = LogisticRegression(random_state = 0, solver='lbfgs')\n",
        "decision_classifier = DecisionTreeClassifier()\n",
        "svm_classifier = SVC()\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
        "naive_classifier = GaussianNB() \n",
        "\n",
        "# We start implementing ensemble methods by first using Bagging Classifiers\n",
        "# ---\n",
        "# Uncomment each classifier and run the respective code\n",
        "# ---\n",
        "bagging_meta_classifier = BaggingClassifier()\n",
        "random_forest_classifier = RandomForestClassifier()\n",
        "\n",
        "# Boosting Classifiers\n",
        "# ---\n",
        "ada_boost_classifier = AdaBoostClassifier()\n",
        "gbm_classifier = GradientBoostingClassifier() \n",
        "xg_boost_classifier = xgb.XGBClassifier() \n",
        "\n",
        "# Now using these classifiers to fit our data, X_train and y_train.\n",
        "# By fitting we mean we train our classifiers based on the train dataset.\n",
        "# ---\n",
        "# Upon running this cell, we should have classifiers that can predict \n",
        "# whether a person will buy a car or not.\n",
        "# ---\n",
        "# Don't worry about the output, we get GaussianNB because our Naive Bayes classifier\n",
        "# is the last one to be built.\n",
        "# ---\n",
        "#\n",
        "logistic_classifier.fit(X_train, y_train)\n",
        "decision_classifier.fit(X_train, y_train)\n",
        "svm_classifier.fit(X_train, y_train)\n",
        "knn_classifier.fit(X_train, y_train)\n",
        "naive_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Bagging Classifiers\n",
        "# ---\n",
        "bagging_meta_classifier.fit(X_train, y_train)\n",
        "random_forest_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Boosting Classifiers\n",
        "# ---\n",
        "ada_boost_classifier.fit(X_train, y_train)\n",
        "gbm_classifier.fit(X_train, y_train)\n",
        "xg_boost_classifier.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
              "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
              "              nthread=None, objective='binary:logistic', random_state=0,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAx-7zU7Tyrt"
      },
      "source": [
        "# We now predict the test set results. \n",
        "# This will help us determine whether our classifiers made the correct predictions.\n",
        "# ---\n",
        "# No expected output here.\n",
        "# ---\n",
        "logistic_y_prediction = logistic_classifier.predict(X_test) \n",
        "decision_y_prediction = decision_classifier.predict(X_test) \n",
        "svm_y_prediction = svm_classifier.predict(X_test) \n",
        "knn_y_prediction = knn_classifier.predict(X_test) \n",
        "naive_y_prediction = naive_classifier.predict(X_test) \n",
        "\n",
        "# Bagging Classifiers\n",
        "# ---\n",
        "bagging_y_classifier = bagging_meta_classifier.predict(X_test) \n",
        "random_forest_y_classifier = random_forest_classifier.predict(X_test) \n",
        "\n",
        "# Boosting Classifiers\n",
        "# ---\n",
        "ada_boost_y_classifier = ada_boost_classifier.predict(X_test)\n",
        "gbm_y_classifier = gbm_classifier.predict(X_test)\n",
        "xg_boost_y_classifier = xg_boost_classifier.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rG_q-tVaUFxy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "7d9052ec-9618-4d7c-b66b-22cb38563a62"
      },
      "source": [
        "# We then import evaluation metrics to determine the accuracy of classifiers\n",
        "# ---\n",
        "# \n",
        "from sklearn.metrics import classification_report, accuracy_score \n",
        "\n",
        "# The accuracy score - is the simplest way to evaluate \n",
        "# However, we note not for a highly imbalance dataset. \n",
        "# By imbalanced we mean that our original dataset would\n",
        "# need to have an equal no's of 1 and 0's\n",
        "# ---\n",
        "print(\"Logistic Regression Classifier\", accuracy_score(logistic_y_prediction, y_test))\n",
        "print(\"Decision Trees Classifier\", accuracy_score(decision_y_prediction, y_test))\n",
        "print(\"SVN Classifier\", accuracy_score(svm_y_prediction, y_test))\n",
        "print(\"KNN Classifier\", accuracy_score(knn_y_prediction, y_test))\n",
        "print(\"Naive Bayes Classifier\", accuracy_score(naive_y_prediction, y_test))\n",
        "\n",
        "# Bagging Classifiers\n",
        "# ---\n",
        "print(\"Bagging Classifier\", accuracy_score(bagging_y_classifier, y_test))\n",
        "print(\"Random Forest Classifier\", accuracy_score(random_forest_y_classifier, y_test))\n",
        "\n",
        "# Boosting Classifiers\n",
        "# ---\n",
        "print(\"Ada Boost Classifier\", accuracy_score(ada_boost_y_classifier, y_test))\n",
        "print(\"GBM Classifier\", accuracy_score(gbm_y_classifier, y_test))\n",
        "print(\"XGBoost Classifier\", accuracy_score(xg_boost_y_classifier, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Logistic Regression Classifier 0.9\n",
            "Decision Trees Classifier 0.91\n",
            "SVN Classifier 0.93\n",
            "KNN Classifier 0.93\n",
            "Naive Bayes Classifier 0.91\n",
            "Bagging Classifier 0.92\n",
            "Random Forest Classifier 0.92\n",
            "Ada Boost Classifier 0.92\n",
            "GBM Classifier 0.91\n",
            "XGBoost Classifier 0.93\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4wgNdhhrdVK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "32490016-2245-477c-f131-321b33e21b00"
      },
      "source": [
        "# We now print the classification report, \n",
        "# which is more reliable for a highly imbalanced dataset. \n",
        "# We use the precision values which give us accuracy values.\n",
        "# \n",
        "# ---\n",
        "# The precision will be \"how many are correctly classified among that class\".\n",
        "# The recall means \"how many of this class you find over the whole number of element of this class\".\n",
        "# The f1-score is the harmonic mean between precision & recall.\n",
        "# The support is the number of occurence of the given class in your dataset.\n",
        "# ---\n",
        "# \n",
        "print('Logistic classifier:')\n",
        "print(classification_report(y_test, logistic_y_prediction))\n",
        "\n",
        "print('Decision Tree classifier:')\n",
        "print(classification_report(y_test, decision_y_prediction))\n",
        "\n",
        "print('SVM Classifier:')\n",
        "print(classification_report(y_test, svm_y_prediction))\n",
        "\n",
        "print('KNN Classifier:')\n",
        "print(classification_report(y_test, knn_y_prediction))\n",
        "\n",
        "print('Naive Bayes Classifier:')\n",
        "print(classification_report(y_test, naive_y_prediction)) \n",
        "\n",
        "# Bagging Classifiers\n",
        "# ---\n",
        "print('Bagging Meta Classifier:')\n",
        "print(classification_report(y_test, bagging_y_classifier)) \n",
        "\n",
        "print('Random Forest Classifier:')\n",
        "print(classification_report(y_test, random_forest_y_classifier)) \n",
        "\n",
        "\n",
        "# Boosting Classifiers\n",
        "# ---\n",
        "print('Ada Boost Classifier:')\n",
        "print(classification_report(y_test, ada_boost_y_classifier)) \n",
        "\n",
        "print('GBM Classifier:')\n",
        "print(classification_report(y_test, gbm_y_classifier)) \n",
        "\n",
        "print('XGBoost Classifier:')\n",
        "print(classification_report(y_test, xg_boost_y_classifier)) \n",
        "\n",
        "# Remember, we can then further perform model opmization techiniques i.e. \n",
        "# data cleaning, feature engineering, checking for model assumptions, etc. \n",
        "# to further get the best classifier. "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Logistic classifier:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.96      0.93        68\n",
            "           1       0.89      0.78      0.83        32\n",
            "\n",
            "    accuracy                           0.90       100\n",
            "   macro avg       0.90      0.87      0.88       100\n",
            "weighted avg       0.90      0.90      0.90       100\n",
            "\n",
            "Decision Tree classifier:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.93      0.93        68\n",
            "           1       0.85      0.88      0.86        32\n",
            "\n",
            "    accuracy                           0.91       100\n",
            "   macro avg       0.89      0.90      0.90       100\n",
            "weighted avg       0.91      0.91      0.91       100\n",
            "\n",
            "SVM Classifier:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.94      0.95        68\n",
            "           1       0.88      0.91      0.89        32\n",
            "\n",
            "    accuracy                           0.93       100\n",
            "   macro avg       0.92      0.92      0.92       100\n",
            "weighted avg       0.93      0.93      0.93       100\n",
            "\n",
            "KNN Classifier:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.94      0.95        68\n",
            "           1       0.88      0.91      0.89        32\n",
            "\n",
            "    accuracy                           0.93       100\n",
            "   macro avg       0.92      0.92      0.92       100\n",
            "weighted avg       0.93      0.93      0.93       100\n",
            "\n",
            "Naive Bayes Classifier:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.97      0.94        68\n",
            "           1       0.93      0.78      0.85        32\n",
            "\n",
            "    accuracy                           0.91       100\n",
            "   macro avg       0.92      0.88      0.89       100\n",
            "weighted avg       0.91      0.91      0.91       100\n",
            "\n",
            "Bagging Meta Classifier:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.94      0.94        68\n",
            "           1       0.88      0.88      0.88        32\n",
            "\n",
            "    accuracy                           0.92       100\n",
            "   macro avg       0.91      0.91      0.91       100\n",
            "weighted avg       0.92      0.92      0.92       100\n",
            "\n",
            "Random Forest Classifier:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.94      0.94        68\n",
            "           1       0.88      0.88      0.88        32\n",
            "\n",
            "    accuracy                           0.92       100\n",
            "   macro avg       0.91      0.91      0.91       100\n",
            "weighted avg       0.92      0.92      0.92       100\n",
            "\n",
            "Ada Boost Classifier:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.94      0.94        68\n",
            "           1       0.88      0.88      0.88        32\n",
            "\n",
            "    accuracy                           0.92       100\n",
            "   macro avg       0.91      0.91      0.91       100\n",
            "weighted avg       0.92      0.92      0.92       100\n",
            "\n",
            "GBM Classifier:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.94      0.93        68\n",
            "           1       0.87      0.84      0.86        32\n",
            "\n",
            "    accuracy                           0.91       100\n",
            "   macro avg       0.90      0.89      0.90       100\n",
            "weighted avg       0.91      0.91      0.91       100\n",
            "\n",
            "XGBoost Classifier:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.94      0.95        68\n",
            "           1       0.88      0.91      0.89        32\n",
            "\n",
            "    accuracy                           0.93       100\n",
            "   macro avg       0.92      0.92      0.92       100\n",
            "weighted avg       0.93      0.93      0.93       100\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnqqUOET9QLu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "8ce051de-2b61-4460-c24c-7d1fd2ed59cf"
      },
      "source": [
        "# Answering our question\n",
        "# ---\n",
        "# We then make a new prediction & compare results.\n",
        "# Note that we would only use the best optimized classifier for this case.\n",
        "# ---\n",
        "# Predict whether John, 60 years old with a salary of 2500 will buy a car or not?\n",
        "# ---\n",
        "# Dataset limitation: This is not a practical dataset, thus dataset will lack essential features/variables.\n",
        "# In a real case scenario, we would work with may kinds of datasets that require transformation\n",
        "# i.e. data cleaning, feature engineering, etc.\n",
        "# ---\n",
        "#\n",
        "new_case = [[1,\t60, 1500]]\n",
        "\n",
        "print(\"Logistic Regression Classifier\", logistic_classifier.predict(new_case))\n",
        "print(\"Decision Tree Classifier\",decision_classifier.predict(new_case))\n",
        "print(\"SVM Classifier\", svm_classifier.predict(new_case))\n",
        "print(\"KNN Classifier\", knn_classifier.predict(new_case))\n",
        "print(\"Naive Bayes Classifier\", naive_classifier.predict(new_case))\n",
        "\n",
        "# Bagging Classifiers\n",
        "# ---\n",
        "print(\"Bagging Meta Classifier\", bagging_meta_classifier.predict(new_case))\n",
        "print(\"Random Forest Classifier\", random_forest_classifier.predict(new_case))\n",
        "\n",
        "# Boosting Classifiers\n",
        "# ---\n",
        "print(\"Ada Boosting Classifier\", ada_boost_classifier.predict(new_case))\n",
        "print(\"GBM Classifier\", gbm_classifier.predict(new_case))\n",
        "print(\"XGBoost Classifier\", xg_boost_classifier.predict(new_case)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Logistic Regression Classifier [1]\n",
            "Decision Tree Classifier [1]\n",
            "SVM Classifier [1]\n",
            "KNN Classifier [1]\n",
            "Naive Bayes Classifier [1]\n",
            "Bagging Meta Classifier [1]\n",
            "Random Forest Classifier [1]\n",
            "Ada Boosting Classifier [1]\n",
            "GBM Classifier [1]\n",
            "XGBoost Classifier [1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaPL6iDf7JIA"
      },
      "source": [
        "### <font color=\"blue\">Regression</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqWcOlZ97JIB"
      },
      "source": [
        "##### <font color=\"blue\">Example</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlQrwW9se7S6"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXpXZxEW7JIC"
      },
      "source": [
        "# Example\n",
        "# --- \n",
        "# Questions: Create a decision tree regression model using the following dataset.\n",
        "# ---\n",
        "# Dataset url = http://bit.ly/FishDatasetClean\n",
        "# NB: This dataset is clean version of the one \n",
        "# we used in the multiple regression example above.\n",
        "# ---\n",
        "# OUR CODE GOES BELOW\n",
        "# "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZdaSxPNmxW9"
      },
      "source": [
        "##### Step 1. Loading our Data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjnbZeaGmioQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "30cf9b19-9f27-4aa0-adf4-09a0be403a67"
      },
      "source": [
        "# Reading our data\n",
        "# ---\n",
        "# \n",
        "df = pd.read_csv('http://bit.ly/FishDatasetClean')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Weight</th>\n",
              "      <th>Length1</th>\n",
              "      <th>Length2</th>\n",
              "      <th>Length3</th>\n",
              "      <th>Height</th>\n",
              "      <th>Width</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>242.0</td>\n",
              "      <td>23.2</td>\n",
              "      <td>25.4</td>\n",
              "      <td>30.0</td>\n",
              "      <td>11.5200</td>\n",
              "      <td>4.0200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>290.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>26.3</td>\n",
              "      <td>31.2</td>\n",
              "      <td>12.4800</td>\n",
              "      <td>4.3056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>340.0</td>\n",
              "      <td>23.9</td>\n",
              "      <td>26.5</td>\n",
              "      <td>31.1</td>\n",
              "      <td>12.3778</td>\n",
              "      <td>4.6961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>363.0</td>\n",
              "      <td>26.3</td>\n",
              "      <td>29.0</td>\n",
              "      <td>33.5</td>\n",
              "      <td>12.7300</td>\n",
              "      <td>4.4555</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>430.0</td>\n",
              "      <td>26.5</td>\n",
              "      <td>29.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>12.4440</td>\n",
              "      <td>5.1340</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Weight  Length1  Length2  Length3   Height   Width\n",
              "0   242.0     23.2     25.4     30.0  11.5200  4.0200\n",
              "1   290.0     24.0     26.3     31.2  12.4800  4.3056\n",
              "2   340.0     23.9     26.5     31.1  12.3778  4.6961\n",
              "3   363.0     26.3     29.0     33.5  12.7300  4.4555\n",
              "4   430.0     26.5     29.0     34.0  12.4440  5.1340"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "477dYK8zNrPc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        },
        "outputId": "72d40654-4e4b-485c-e0a1-ceb36b983c89"
      },
      "source": [
        "# Describing our dataset\n",
        "# ---\n",
        "# \n",
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Weight</th>\n",
              "      <th>Length1</th>\n",
              "      <th>Length2</th>\n",
              "      <th>Length3</th>\n",
              "      <th>Height</th>\n",
              "      <th>Width</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>159.000000</td>\n",
              "      <td>159.000000</td>\n",
              "      <td>159.000000</td>\n",
              "      <td>159.000000</td>\n",
              "      <td>159.000000</td>\n",
              "      <td>159.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>398.326415</td>\n",
              "      <td>26.247170</td>\n",
              "      <td>28.415723</td>\n",
              "      <td>31.227044</td>\n",
              "      <td>8.970994</td>\n",
              "      <td>4.417486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>357.978317</td>\n",
              "      <td>9.996441</td>\n",
              "      <td>10.716328</td>\n",
              "      <td>11.610246</td>\n",
              "      <td>4.286208</td>\n",
              "      <td>1.685804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.500000</td>\n",
              "      <td>8.400000</td>\n",
              "      <td>8.800000</td>\n",
              "      <td>1.728400</td>\n",
              "      <td>1.047600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>120.000000</td>\n",
              "      <td>19.050000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>23.150000</td>\n",
              "      <td>5.944800</td>\n",
              "      <td>3.385650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>273.000000</td>\n",
              "      <td>25.200000</td>\n",
              "      <td>27.300000</td>\n",
              "      <td>29.400000</td>\n",
              "      <td>7.786000</td>\n",
              "      <td>4.248500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>650.000000</td>\n",
              "      <td>32.700000</td>\n",
              "      <td>35.500000</td>\n",
              "      <td>39.650000</td>\n",
              "      <td>12.365900</td>\n",
              "      <td>5.584500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1650.000000</td>\n",
              "      <td>59.000000</td>\n",
              "      <td>63.400000</td>\n",
              "      <td>68.000000</td>\n",
              "      <td>18.957000</td>\n",
              "      <td>8.142000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Weight     Length1     Length2     Length3      Height       Width\n",
              "count   159.000000  159.000000  159.000000  159.000000  159.000000  159.000000\n",
              "mean    398.326415   26.247170   28.415723   31.227044    8.970994    4.417486\n",
              "std     357.978317    9.996441   10.716328   11.610246    4.286208    1.685804\n",
              "min       0.000000    7.500000    8.400000    8.800000    1.728400    1.047600\n",
              "25%     120.000000   19.050000   21.000000   23.150000    5.944800    3.385650\n",
              "50%     273.000000   25.200000   27.300000   29.400000    7.786000    4.248500\n",
              "75%     650.000000   32.700000   35.500000   39.650000   12.365900    5.584500\n",
              "max    1650.000000   59.000000   63.400000   68.000000   18.957000    8.142000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfdApR7Jmzm9"
      },
      "source": [
        "##### Step 2, 3, 4: Checking, Cleaning, Exploratory Analysis and have already been performed on our dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eBPjiM8m14s"
      },
      "source": [
        "##### Step 5. Implementation and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rprclJHCmiQA"
      },
      "source": [
        "# Let's now split our dataset\n",
        "# ---\n",
        "# \n",
        "# Firstly, importing our train_test_split function\n",
        "# ---\n",
        "#\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df[['Length1', 'Length2', 'Length3', 'Height', 'Width']]\n",
        "y = df['Weight']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xM2qYhp2miKc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "15e33ab1-9dbf-4e79-ca4b-af4b21ae047b"
      },
      "source": [
        "# Lets now train our regressors\n",
        "# ---\n",
        "#  \n",
        "\n",
        "from sklearn.tree import DecisionTreeRegressor \n",
        "from sklearn.ensemble import BaggingRegressor \n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "import xgboost as xgb\n",
        "\n",
        "\n",
        "# Creating our regressors, We'll just use the decision tree regressor this time\n",
        "# ---\n",
        "# \n",
        "regressor = DecisionTreeRegressor()\n",
        "\n",
        "# Then creating our ensemble regressors\n",
        "# ---\n",
        "\n",
        "# Bagging Regressors\n",
        "# ---\n",
        "bagging_est_regressor = BaggingRegressor()\n",
        "random_forest_regressor = RandomForestRegressor()\n",
        "\n",
        "# Boosting Regressors\n",
        "# ---\n",
        "ada_boost_regressor = AdaBoostRegressor()\n",
        "gbm_regressor = GradientBoostingRegressor()\n",
        "xgboost_regressor = xgb.XGBRegressor(objective ='reg:squarederror') # It requires us to specify the objective function\n",
        "\n",
        "# Fitting our data to our regressors \n",
        "# ---\n",
        "# Decision Tree Regressor\n",
        "regressor.fit(X_train, y_train)\n",
        "\n",
        "# Bagging Regressors\n",
        "# ---\n",
        "bagging_est_regressor.fit(X_train, y_train)\n",
        "random_forest_regressor.fit(X_train, y_train)\n",
        "\n",
        "# Boosting Regressors\n",
        "# ---\n",
        "ada_boost_regressor.fit(X_train, y_train)\n",
        "gbm_regressor.fit(X_train, y_train)\n",
        "xgboost_regressor.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "             colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "             importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
              "             max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
              "             n_jobs=1, nthread=None, objective='reg:squarederror',\n",
              "             random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
              "             seed=None, silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9FqCDpRpahT"
      },
      "source": [
        "# Making predictions using our models\n",
        "# ---\n",
        "#  \n",
        "y_pred = regressor.predict(X_test)\n",
        "\n",
        "# Bagging Regressors\n",
        "# ---\n",
        "bag_est_y_pred = bagging_est_regressor.predict(X_test)\n",
        "random_forest_y_pred = random_forest_regressor.predict(X_test)\n",
        "\n",
        "# Boosting Regressors\n",
        "# ---\n",
        "ada_boost_y_pred = ada_boost_regressor.predict(X_test)\n",
        "gbm_y_pred = gbm_regressor.predict(X_test)\n",
        "xgboost_y_pred = xgboost_regressor.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8n51lYFVs9tg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "fccb0c82-a0ca-4acb-dba1-85391780146f"
      },
      "source": [
        "# Next, we compare actual output values for X_test with the predicted values\n",
        "# ---\n",
        "#\n",
        "df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
        "df.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Actual</th>\n",
              "      <th>Predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>390.0</td>\n",
              "      <td>430.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>0.0</td>\n",
              "      <td>140.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>170.0</td>\n",
              "      <td>150.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>160.0</td>\n",
              "      <td>160.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110</th>\n",
              "      <td>556.0</td>\n",
              "      <td>690.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Actual  Predicted\n",
              "7     390.0      430.0\n",
              "40      0.0      140.0\n",
              "95    170.0      150.0\n",
              "45    160.0      160.0\n",
              "110   556.0      690.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ryp4KnEUP2yP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "476a6d88-ba53-4f81-8e7e-51f470af6447"
      },
      "source": [
        "# We make predictings for the random forest regressor\n",
        "# ---\n",
        "# Next, we compare actual output values for X_test with the predicted values\n",
        "# ---\n",
        "random_forest_df = pd.DataFrame({'Actual': y_test, 'Predicted': random_forest_y_pred})\n",
        "random_forest_df.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Actual</th>\n",
              "      <th>Predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>390.0</td>\n",
              "      <td>425.69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>0.0</td>\n",
              "      <td>127.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>170.0</td>\n",
              "      <td>163.31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>160.0</td>\n",
              "      <td>156.87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110</th>\n",
              "      <td>556.0</td>\n",
              "      <td>666.90</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Actual  Predicted\n",
              "7     390.0     425.69\n",
              "40      0.0     127.00\n",
              "95    170.0     163.31\n",
              "45    160.0     156.87\n",
              "110   556.0     666.90"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNWV3e5RIBks",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "0466ddb8-96d3-4adb-def3-05b2cf8d6608"
      },
      "source": [
        "# We make predictions for the adaboost regressor\n",
        "# ---\n",
        "# Next, we compare actual output values for X_test with the predicted values\n",
        "# ---\n",
        "ada_boost_df = pd.DataFrame({'Actual': y_test, 'Predicted': ada_boost_y_pred})\n",
        "ada_boost_df.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Actual</th>\n",
              "      <th>Predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>390.0</td>\n",
              "      <td>396.366667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>0.0</td>\n",
              "      <td>142.230769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>170.0</td>\n",
              "      <td>146.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>160.0</td>\n",
              "      <td>150.941176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110</th>\n",
              "      <td>556.0</td>\n",
              "      <td>640.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Actual   Predicted\n",
              "7     390.0  396.366667\n",
              "40      0.0  142.230769\n",
              "95    170.0  146.000000\n",
              "45    160.0  150.941176\n",
              "110   556.0  640.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7jzgfuWRui6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "00fc924c-6d96-4770-8542-238bb06b1c40"
      },
      "source": [
        "# We make predictions for the gbm regressor\n",
        "# ---\n",
        "# Next, we compare actual output values for X_test with the predicted values\n",
        "# ---\n",
        "gbm_df = pd.DataFrame({'Actual': y_test, 'Predicted': gbm_y_pred})\n",
        "gbm_df.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Actual</th>\n",
              "      <th>Predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>390.0</td>\n",
              "      <td>434.394032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>0.0</td>\n",
              "      <td>130.844108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>170.0</td>\n",
              "      <td>162.803669</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>160.0</td>\n",
              "      <td>152.770039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110</th>\n",
              "      <td>556.0</td>\n",
              "      <td>695.941056</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Actual   Predicted\n",
              "7     390.0  434.394032\n",
              "40      0.0  130.844108\n",
              "95    170.0  162.803669\n",
              "45    160.0  152.770039\n",
              "110   556.0  695.941056"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvtwjGM-VpcP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "8a97e40c-5e6a-46ac-c6f5-b21459f07938"
      },
      "source": [
        "# We also predict for the XGboost regressor\n",
        "# ---\n",
        "# Next, we compare actual output values for X_test with the predicted values\n",
        "# ---\n",
        "xgboost_df = pd.DataFrame({'Actual': y_test, 'Predicted': xgboost_y_pred})\n",
        "xgboost_df.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Actual</th>\n",
              "      <th>Predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>390.0</td>\n",
              "      <td>444.598541</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>0.0</td>\n",
              "      <td>130.755463</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>170.0</td>\n",
              "      <td>162.332397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>160.0</td>\n",
              "      <td>149.509171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110</th>\n",
              "      <td>556.0</td>\n",
              "      <td>701.653015</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Actual   Predicted\n",
              "7     390.0  444.598541\n",
              "40      0.0  130.755463\n",
              "95    170.0  162.332397\n",
              "45    160.0  149.509171\n",
              "110   556.0  701.653015"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuOEMtNDmh9O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "caf3dc5c-b60a-4dbf-d19a-b471f2e9d92b"
      },
      "source": [
        "# Finally, we evaluate the models\n",
        "# ---  \n",
        "# NB: The closer the RMSE is to 0, the better the model.\n",
        "#  \n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "print('Decision Tree - Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, y_pred)))\n",
        "\n",
        "# Bagging Regressors\n",
        "# ---\n",
        "print('Bagging Estimator - Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, bag_est_y_pred)))\n",
        "print('Random Forest - Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, random_forest_y_pred)))\n",
        "\n",
        "# Boosting Regressors\n",
        "# ---\n",
        "print('Ada Boost - Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, ada_boost_y_pred)))\n",
        "print('GBM - Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, gbm_y_pred)))\n",
        "print('XGBoost - Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, xgboost_y_pred)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decision Tree - Root Mean Squared Error: 187.11269609961442\n",
            "Bagging Estimator - Root Mean Squared Error: 157.89943361994685\n",
            "Random Forest - Root Mean Squared Error: 159.7836546309702\n",
            "Ada Boost - Root Mean Squared Error: 177.6687256431936\n",
            "GBM - Root Mean Squared Error: 149.67887602143222\n",
            "XGBoost - Root Mean Squared Error: 144.584484457552\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBSYp3fVIupH"
      },
      "source": [
        "##<font color=\"green\">Challenges</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uebT2koxr4V4"
      },
      "source": [
        "###<font color=\"green\">Challenge 1</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVcDuh88sFLE"
      },
      "source": [
        "# Challenge 1\n",
        "# ---\n",
        "# Question: A cancer medical reasearch institution would like to make predictions on two different \n",
        "# cancer types benign and malignant. Build a model to predict the breast cancer type \n",
        "# (0 = benign or 1 = malignant) given the following dataset. In addition, make a prediction.\n",
        "# NB: Remember to record your observations and also implement ensemble techniques with the goal of improving accuracy.\n",
        "# Make a recommendation on the best model to use for this problem.\n",
        "# ---\n",
        "# Dataset url = http://bit.ly/BreastCancersDataset\n",
        "# ---\n",
        "# OUR CODE GOES BELOW\n",
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-eE6btO3KKM"
      },
      "source": [
        "###<font color=\"green\">Challenge 2</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9b-Q2CMI2wg1"
      },
      "source": [
        "# Challenge \n",
        "# ---\n",
        "# Predict the price of cars comparing your models using the following dataset. \n",
        "# Make a recommendation on the best model to use for this problem.\n",
        "# ---\n",
        "# Dataset url = http://bit.ly/CarPriceDataset\n",
        "# ---\n",
        "# OUR CODE GOES BELOW\n",
        "#"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}